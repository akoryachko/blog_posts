{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Py(Spark)\n",
    "\n",
    "\"PySpark is the Python API for Apache Spark, a distributed computing framework for large-scale data processing.\"\n",
    "\n",
    "Let's disect this sentence:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python API\n",
    "\n",
    "This basically means a way to use Python to interact with Spark.\n",
    "\n",
    "Spark is written in Scala but you can interact with Spark in several ways (e.g, R, Java and Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large-scale data processing\n",
    "\n",
    "Spark can process Terabytes of data, and with some effort can scale up to Petabytes (https://www.databricks.com/blog/2014/10/10/spark-petabyte-sort.html)\n",
    "\n",
    "So seriously big data processing is possible; you just need a large enough cluster/wallet.\n",
    "\n",
    "\n",
    "Sidenote: It does however also mean that Spark is not very well suited for small data (up to a few million rows), it will work, but the overhead will be large. Pandas/Polars/Python would be better suited for analysis on small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed computing framework\n",
    "Distributed computing is the method of making multiple computers work together to solve a common problem.\n",
    "\n",
    "For example, we need to perform some operations on a 100 GB file. Processing this data on a single machine can take hours or maybe days based on the operation. \n",
    "However, if the same file could be broken down into 100 files of 1GB each and then processed in parallel, our total time taken would become approximately 1/100th.\n",
    "\n",
    "A Spark cluster consists of the following components shown in the image below:\n",
    "\n",
    "For more background information, see: https://spark.apache.org/docs/latest/cluster-overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/neilclack/nyc-taxi-trip-data-google-public-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/01 14:11:16 WARN Utils: Your hostname, Alexandrs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.51.45.161 instead (on interface en0)\n",
      "24/08/01 14:11:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/01 14:11:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"myAppName\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: reading the trips dataset from taxi_trip_data.csv file in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf_trips = spark.read.csv(\"data/taxi_trip_data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: read the geo zones dataset from the taxi_zone_geo.csv file in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_geo = spark.read.csv(\"data/taxi_zone_geo.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Display rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: show a sample of 5 records from sdf_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|        2|2018-03-29 13:37:13|2018-03-29 14:17:01|              1|        18.15|        3|                 N|           1|       70.0|  0.0|    0.0|     16.16|        10.5|          0.3|       96.96|               161|                  1|\n",
      "|        2|2018-03-29 13:37:18|2018-03-29 14:15:33|              1|         4.59|        1|                 N|           1|       25.0|  0.0|    0.5|      5.16|         0.0|          0.3|       30.96|                13|                230|\n",
      "|        2|2018-03-29 13:26:57|2018-03-29 13:28:03|              1|          0.3|        1|                 N|           1|        3.0|  0.0|    0.5|      0.76|         0.0|          0.3|        4.56|               231|                231|\n",
      "|        2|2018-03-29 13:07:48|2018-03-29 14:03:05|              2|        16.97|        1|                 N|           1|       49.5|  0.0|    0.5|      5.61|        5.76|          0.3|       61.67|               231|                138|\n",
      "|        2|2018-03-29 14:19:11|2018-03-29 15:19:59|              5|        14.45|        1|                 N|           1|       45.5|  0.0|    0.5|     10.41|        5.76|          0.3|       62.47|                87|                138|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_trips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: show a sample of 3 records from sdf_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+--------------------+\n",
      "|zone_id|           zone_name|borough|           zone_geom|\n",
      "+-------+--------------------+-------+--------------------+\n",
      "|      1|      Newark Airport|    EWR|POLYGON((-74.1856...|\n",
      "|      3|Allerton/Pelham G...|  Bronx|POLYGON((-73.8485...|\n",
      "|     18|        Bedford Park|  Bronx|POLYGON((-73.8844...|\n",
      "+-------+--------------------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_geo.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: show the top 3 most used payment types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|payment_type|  count|\n",
      "+------------+-------+\n",
      "|           1|8255092|\n",
      "|           2|1623133|\n",
      "|           3|  95464|\n",
      "+------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .groupBy('payment_type')\n",
    "    .count()\n",
    "    .sort(F.desc('count'))\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: show the top 3 borough names with the most zone ids\n",
    "\n",
    "Extra credit for displaying the percentage of total zone ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+----------+\n",
      "|      borough|count|percentage|\n",
      "+-------------+-----+----------+\n",
      "|       Queens|   69|    26.24%|\n",
      "|    Manhattan|   69|    26.24%|\n",
      "|     Brooklyn|   61|    23.19%|\n",
      "|        Bronx|   43|    16.35%|\n",
      "|Staten Island|   20|     7.60%|\n",
      "+-------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "geo_row_count = sdf_geo.count()\n",
    "\n",
    "(\n",
    "    sdf_geo\n",
    "    .groupBy('borough')\n",
    "    .count()\n",
    "    .sort(F.desc('count'))\n",
    "    .withColumn('percentage', F.format_string('%2.2f%%', 100*F.col('count')/geo_row_count))\n",
    "    .drop('all_counts')\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: count of the rides with more than 3 passengers in the year May of 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/01 14:11:29 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 15:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64,864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n_full_car_rides = (\n",
    "    sdf_trips\n",
    "    .filter(F.date_format(F.col('pickup_datetime'), \"MMyyyy\") == \"052018\")\n",
    "    .filter(F.col('passenger_count') > 4)\n",
    ").count()\n",
    "\n",
    "print(f\"{n_full_car_rides:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: find the cost of the most expensive ride that ended between 5pm and 6pm made paid with the payment type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$699.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cost_evening_ride = (\n",
    "    sdf_trips\n",
    "    # .withColumn(\"hours\", F.date_format(F.col('pickup_datetime'), \"HH\"))\n",
    "    .filter(F.date_format(F.col('dropoff_datetime'), \"HH\") == \"17\")\n",
    "    .filter(F.col('payment_type') == 1)\n",
    "    .agg(F.max(\"fare_amount\"))\n",
    ").collect()[0][0]\n",
    "\n",
    "print(f\"${cost_evening_ride:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Deduplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: keep only one trip for each unique combination of passenger_count and rate_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/01 14:11:33 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 21:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|        1|2018-11-01 15:36:34|2018-11-01 16:08:56|              0|          8.0|        1|                 N|           1|       27.5|  0.0|    0.5|      5.65|         0.0|          0.3|       33.95|               138|                255|\n",
      "|        1|2018-10-31 14:49:28|2018-10-31 16:08:42|              0|         27.5|        2|                 N|           1|       52.0|  0.0|    0.5|      11.7|        5.76|          0.3|       70.26|               132|                 13|\n",
      "|        1|2018-11-28 13:04:16|2018-11-28 13:38:57|              0|         18.0|        3|                 N|           1|       69.0|  0.0|    0.0|     15.95|        10.5|          0.3|       95.75|               161|                  1|\n",
      "|        1|2018-12-15 13:30:18|2018-12-15 14:05:28|              0|         19.9|        4|                 N|           1|       61.5|  0.0|    0.5|      13.6|        5.76|          0.3|       81.66|                80|                265|\n",
      "|        1|2018-08-11 18:06:47|2018-08-11 18:07:03|              0|         10.0|        5|                 N|           1|       64.0|  0.0|    0.0|      10.0|         0.0|          0.3|        74.3|               230|                230|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .dropDuplicates(subset=[\"passenger_count\", \"rate_code\"])\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: keep only one zone id for each zone name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           zone_name|count|\n",
      "+--------------------+-----+\n",
      "|           Homecrest|    1|\n",
      "|Governor's Island...|    1|\n",
      "|              Corona|    1|\n",
      "|    Bensonhurst West|    1|\n",
      "|         Westerleigh|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_geo\n",
    "    .dropDuplicates(subset=[\"zone_name\"])\n",
    "    .groupBy('zone_name')\n",
    "    .count()\n",
    "    .sort(F.desc('count'))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Change conditionally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: reduce the `tolls_amount` by half for the trips that started and ended in the different zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+--------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|new_toll|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+--------+\n",
      "|        2|2018-03-29 13:37:13|2018-03-29 14:17:01|              1|        18.15|        3|                 N|           1|       70.0|  0.0|    0.0|     16.16|        10.5|          0.3|       96.96|               161|                  1|    5.25|\n",
      "|        2|2018-03-29 13:37:18|2018-03-29 14:15:33|              1|         4.59|        1|                 N|           1|       25.0|  0.0|    0.5|      5.16|         0.0|          0.3|       30.96|                13|                230|     0.0|\n",
      "|        2|2018-03-29 13:26:57|2018-03-29 13:28:03|              1|          0.3|        1|                 N|           1|        3.0|  0.0|    0.5|      0.76|         0.0|          0.3|        4.56|               231|                231|     0.0|\n",
      "|        2|2018-03-29 13:07:48|2018-03-29 14:03:05|              2|        16.97|        1|                 N|           1|       49.5|  0.0|    0.5|      5.61|        5.76|          0.3|       61.67|               231|                138|    2.88|\n",
      "|        2|2018-03-29 14:19:11|2018-03-29 15:19:59|              5|        14.45|        1|                 N|           1|       45.5|  0.0|    0.5|     10.41|        5.76|          0.3|       62.47|                87|                138|    2.88|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"new_toll\",\n",
    "        F.when(F.col(\"pickup_location_id\") != F.col(\"dropoff_location_id\"), F.col(\"tolls_amount\") * 0.5)\n",
    "        .otherwise(F.col(\"tolls_amount\"))\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: set the negative fare_amount to 0 for the negative fares and cap the positive ones by $10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|        2|2018-03-29 13:37:13|2018-03-29 14:17:01|              1|        18.15|        3|                 N|           1|       10.0|  0.0|    0.0|     16.16|        10.5|          0.3|       96.96|               161|                  1|\n",
      "|        2|2018-03-29 13:37:18|2018-03-29 14:15:33|              1|         4.59|        1|                 N|           1|       10.0|  0.0|    0.5|      5.16|         0.0|          0.3|       30.96|                13|                230|\n",
      "|        2|2018-03-29 13:26:57|2018-03-29 13:28:03|              1|          0.3|        1|                 N|           1|        3.0|  0.0|    0.5|      0.76|         0.0|          0.3|        4.56|               231|                231|\n",
      "|        2|2018-03-29 13:07:48|2018-03-29 14:03:05|              2|        16.97|        1|                 N|           1|       10.0|  0.0|    0.5|      5.61|        5.76|          0.3|       61.67|               231|                138|\n",
      "|        2|2018-03-29 14:19:11|2018-03-29 15:19:59|              5|        14.45|        1|                 N|           1|       10.0|  0.0|    0.5|     10.41|        5.76|          0.3|       62.47|                87|                138|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"fare_amount\",\n",
    "        F.when(F.col(\"fare_amount\") < 0, F.lit(0))\n",
    "        .when(F.col(\"fare_amount\") > 10, F.lit(10))\n",
    "        .otherwise(F.col(\"fare_amount\"))\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: how many single passengers were picked up in Bronx borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20,057 single Bronx rides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n_single_bronx_rides = (\n",
    "    sdf_trips\n",
    "    .filter(F.col(\"passenger_count\") == 1)\n",
    "    .join(\n",
    "        sdf_geo\n",
    "        .filter(F.col(\"borough\") == \"Bronx\"),\n",
    "        sdf_trips.pickup_location_id == sdf_geo.zone_id,\n",
    "        how=\"inner\",\n",
    "    )\n",
    ").count()\n",
    "\n",
    "print(f\"{n_single_bronx_rides:,} single Bronx rides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: What is the longest ride to JFK Airport zone for less than $20?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price for the longest cheap trip: $132.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "longest_cheap_trip = (\n",
    "    sdf_trips\n",
    "    .filter(F.col(\"passenger_count\") == 1)\n",
    "    .join(\n",
    "        sdf_geo\n",
    "        .filter(F.col(\"zone_name\") == \"JFK Airport\"),\n",
    "        sdf_trips.dropoff_location_id == sdf_geo.zone_id,\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .filter(F.col(\"fare_amount\") < 20)\n",
    "    .sort(F.desc(\"trip_distance\"))\n",
    "    .limit(1)\n",
    ").collect()[0][\"trip_distance\"]\n",
    "\n",
    "print(f\"Price for the longest cheap trip: ${longest_cheap_trip:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. User defined functions\n",
    "When you think you ran out of Pyspark native options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: round up the tip amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def spark_ceil(x):\n",
    "    return ceil(x)\n",
    "\n",
    "spark_ceil_udf = F.udf(spark_ceil, T.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|tip_amount_rounded_up|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------------------+\n",
      "|        2|2018-03-29 13:37:13|2018-03-29 14:17:01|              1|        18.15|        3|                 N|           1|       70.0|  0.0|    0.0|     16.16|        10.5|          0.3|       96.96|               161|                  1|                   17|\n",
      "|        2|2018-03-29 13:37:18|2018-03-29 14:15:33|              1|         4.59|        1|                 N|           1|       25.0|  0.0|    0.5|      5.16|         0.0|          0.3|       30.96|                13|                230|                    6|\n",
      "|        2|2018-03-29 13:26:57|2018-03-29 13:28:03|              1|          0.3|        1|                 N|           1|        3.0|  0.0|    0.5|      0.76|         0.0|          0.3|        4.56|               231|                231|                    1|\n",
      "|        2|2018-03-29 13:07:48|2018-03-29 14:03:05|              2|        16.97|        1|                 N|           1|       49.5|  0.0|    0.5|      5.61|        5.76|          0.3|       61.67|               231|                138|                    6|\n",
      "|        2|2018-03-29 14:19:11|2018-03-29 15:19:59|              5|        14.45|        1|                 N|           1|       45.5|  0.0|    0.5|     10.41|        5.76|          0.3|       62.47|                87|                138|                   11|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\"tip_amount_rounded_up\", spark_ceil_udf(F.col(\"tip_amount\")))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: calculate cosine of the tolls amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos\n",
    "\n",
    "def spark_cos(x):\n",
    "    return cos(x)\n",
    "\n",
    "spark_cos_udf = F.udf(spark_cos, T.FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|cos_tolls_amount|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------------+\n",
      "|        2|2018-03-29 13:37:13|2018-03-29 14:17:01|              1|        18.15|        3|                 N|           1|       70.0|  0.0|    0.0|     16.16|        10.5|          0.3|       96.96|               161|                  1|     -0.47553694|\n",
      "|        2|2018-03-29 13:37:18|2018-03-29 14:15:33|              1|         4.59|        1|                 N|           1|       25.0|  0.0|    0.5|      5.16|         0.0|          0.3|       30.96|                13|                230|             1.0|\n",
      "|        2|2018-03-29 13:26:57|2018-03-29 13:28:03|              1|          0.3|        1|                 N|           1|        3.0|  0.0|    0.5|      0.76|         0.0|          0.3|        4.56|               231|                231|             1.0|\n",
      "|        2|2018-03-29 13:07:48|2018-03-29 14:03:05|              2|        16.97|        1|                 N|           1|       49.5|  0.0|    0.5|      5.61|        5.76|          0.3|       61.67|               231|                138|      0.86623204|\n",
      "|        2|2018-03-29 14:19:11|2018-03-29 15:19:59|              5|        14.45|        1|                 N|           1|       45.5|  0.0|    0.5|     10.41|        5.76|          0.3|       62.47|                87|                138|      0.86623204|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\"cos_tolls_amount\", spark_cos_udf(F.col(\"tolls_amount\")))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transformations within slices/windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: keep the 3 latest rides from each pickup zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|row_number|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+\n",
      "|        1|2018-12-31 15:04:52|2018-12-31 15:05:25|              1|         13.2|        5|                 N|           1|      162.5|  0.0|    0.0|      28.0|         0.0|          0.3|       190.8|                 1|                  1|         1|\n",
      "|        1|2018-12-31 14:07:13|2018-12-31 14:07:28|              2|          0.5|        5|                 N|           1|       95.0|  0.0|    0.0|       4.7|         0.0|          0.3|       100.0|                 1|                  1|         2|\n",
      "|        1|2018-12-31 13:36:54|2018-12-31 13:37:16|              2|          0.9|        5|                 N|           1|      120.0|  0.0|    0.0|      15.0|         0.0|          0.3|       135.3|                 1|                  1|         3|\n",
      "|        2|2018-12-29 22:57:08|2018-12-29 23:33:25|              5|        20.78|        2|                 N|           2|       52.0|  0.0|    0.5|       0.0|         0.0|          0.3|        52.8|                 2|                144|         1|\n",
      "|        2|2018-12-17 17:50:00|2018-12-17 18:47:54|              2|        18.24|        2|                 N|           1|       52.0|  4.5|    0.5|     11.46|         0.0|          0.3|       68.76|                 2|                143|         2|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"row_number\",\n",
    "        F.row_number()\n",
    "        .over(\n",
    "            Window\n",
    "            .partitionBy(\"pickup_location_id\")\n",
    "            .orderBy(F.desc(\"pickup_datetime\"))\n",
    "        )\n",
    "    )\n",
    "    .filter(F.col(\"row_number\") < 4)\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: calculate a cumulative sum of mta_tax starting from the earliest for each payment type\n",
    "\n",
    "Extra credit: how many trips did it take to accumulate $5 in mta_tax for each payment type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/01 14:12:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 44:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|payment_type|trips_count|\n",
      "+------------+-----------+\n",
      "|           1|         10|\n",
      "|           3|         14|\n",
      "|           4|         54|\n",
      "|           5|       NULL|\n",
      "|           2|         10|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "TO_ACCUMULATE = 5\n",
    "\n",
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"cumulative_mta_tax\",\n",
    "        F.sum(\"mta_tax\")\n",
    "        .over(\n",
    "            Window\n",
    "            .partitionBy(\"payment_type\")\n",
    "            .orderBy(F.col(\"pickup_datetime\"))\n",
    "            .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "        )\n",
    "    )\n",
    "    .filter(F.col(\"cumulative_mta_tax\") <= TO_ACCUMULATE)\n",
    "    .groupBy(\"payment_type\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips_count\"),\n",
    "        F.max(\"cumulative_mta_tax\").alias(\"max_cum\")\n",
    "    )\n",
    "    .select(\n",
    "        \"payment_type\",\n",
    "        F.when(F.col(\"max_cum\") >= TO_ACCUMULATE, F.col(\"trips_count\"))\n",
    "        .otherwise(F.lit(None))\n",
    "        .alias(\"trips_count\")\n",
    "    )\n",
    ").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Structures and Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: put pickup and dropoff locations to the zone_ids structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendor_id: integer (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- rate_code: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- imp_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- zone_ids: struct (nullable = false)\n",
      " |    |-- pickup_location_id: integer (nullable = true)\n",
      " |    |-- dropoff_location_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"zone_ids\",\n",
    "        F.struct('pickup_location_id','dropoff_location_id')\n",
    "    )\n",
    ").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: create a column that would hold a structure called payments that would include the total and substructure with all the contributions to this payment\n",
    "\n",
    "**Task 2**: create a dataframe `sdf_structured` with the column above while the contributing columns are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendor_id: integer (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- rate_code: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- imp_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- payments: struct (nullable = false)\n",
      " |    |-- contributions: struct (nullable = false)\n",
      " |    |    |-- fare_amount: double (nullable = true)\n",
      " |    |    |-- extra: double (nullable = true)\n",
      " |    |    |-- mta_tax: double (nullable = true)\n",
      " |    |    |-- tip_amount: double (nullable = true)\n",
      " |    |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_structured = (\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"contributions\",\n",
    "        F.struct(*sdf_trips.columns[8:12])\n",
    "    )\n",
    "    .withColumn(\n",
    "        'payments',\n",
    "        F.struct(\"contributions\", \"total_amount\")\n",
    "    )\n",
    "    .drop(*sdf_trips.columns[8:13])\n",
    "    .drop(\"contributions\")\n",
    ")\n",
    "\n",
    "sdf_structured.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: collect an array of trip distances for each `passenger_count`, `rate_code`, and `payment_type` combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+------------+--------------------+\n",
      "|passenger_count|rate_code|payment_type|           distances|\n",
      "+---------------+---------+------------+--------------------+\n",
      "|              1|        5|           3|[0.0, 8.0, 0.0, 0...|\n",
      "|              3|        2|           3|[0.33, 0.06, 0.0,...|\n",
      "|              5|        4|           2|[8.38, 21.58, 16....|\n",
      "|              3|        1|           4|[9.8, 6.1, 0.21, ...|\n",
      "|              3|        3|           1|[16.6, 17.6, 17.6...|\n",
      "+---------------+---------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .groupBy(\n",
    "        \"passenger_count\",\n",
    "        \"rate_code\",\n",
    "        \"payment_type\",\n",
    "    )\n",
    "    .agg(\n",
    "        F.collect_list('trip_distance').alias('distances')\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: create a column that holds the 5 latest payments structures from `sdf_structured` for each pickup location and store the resulting data frame as `sdf_structured_arrayed`\n",
    "\n",
    "**Extra Credit**: extract the 3rd tip amount from the array for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- zone_id: integer (nullable = true)\n",
      " |-- payments: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = false)\n",
      " |    |    |-- contributions: struct (nullable = false)\n",
      " |    |    |    |-- fare_amount: double (nullable = true)\n",
      " |    |    |    |-- extra: double (nullable = true)\n",
      " |    |    |    |-- mta_tax: double (nullable = true)\n",
      " |    |    |    |-- tip_amount: double (nullable = true)\n",
      " |    |    |-- total_amount: double (nullable = true)\n",
      " |-- zone_name: string (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      " |-- zone_geom: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+\n",
      "|           zone_name|            payments|the_trird_tip|\n",
      "+--------------------+--------------------+-------------+\n",
      "|      Newark Airport|[{{162.5, 0.0, 0....|         15.0|\n",
      "|         Jamaica Bay|[{{52.0, 0.0, 0.5...|         14.6|\n",
      "|Allerton/Pelham G...|[{{45.0, 0.0, 0.0...|          0.0|\n",
      "|       Alphabet City|[{{37.0, 0.5, 0.5...|          0.0|\n",
      "|       Arden Heights|[{{78.5, 0.0, 0.5...|          0.0|\n",
      "+--------------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf_structured_arrayed = (\n",
    "    sdf_structured\n",
    "    .withColumn(\n",
    "        \"row_number\",\n",
    "        F.row_number()\n",
    "        .over(\n",
    "            Window\n",
    "            .partitionBy(\"pickup_location_id\")\n",
    "            .orderBy(F.desc(\"pickup_datetime\"))\n",
    "        )\n",
    "    )\n",
    "    .filter(F.col(\"row_number\") < 6)\n",
    "    .groupBy(\"pickup_location_id\")\n",
    "    .agg(\n",
    "        F.collect_list('payments').alias('payments')\n",
    "    )\n",
    "    .withColumnRenamed(\"pickup_location_id\", \"zone_id\")\n",
    "    .join(\n",
    "        sdf_geo,\n",
    "        on=\"zone_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "sdf_structured_arrayed.printSchema()\n",
    "\n",
    "(\n",
    "    sdf_structured_arrayed\n",
    "    .select(\n",
    "        \"zone_name\",\n",
    "        \"payments\",\n",
    "        (F.col(\"payments.contributions.tip_amount\")[2]).alias('the_trird_tip')\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Extract data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Extract total amount from `sdf_structured` into individual rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+-------+--------------------+------------+\n",
      "|zone_id|            payments|     zone_name|borough|           zone_geom|total_amount|\n",
      "+-------+--------------------+--------------+-------+--------------------+------------+\n",
      "|      1|{{162.5, 0.0, 0.0...|Newark Airport|    EWR|POLYGON((-74.1856...|       190.8|\n",
      "|      1|{{95.0, 0.0, 0.0,...|Newark Airport|    EWR|POLYGON((-74.1856...|       100.0|\n",
      "|      1|{{120.0, 0.0, 0.0...|Newark Airport|    EWR|POLYGON((-74.1856...|       135.3|\n",
      "|      1|{{80.0, 0.0, 0.0,...|Newark Airport|    EWR|POLYGON((-74.1856...|      114.35|\n",
      "|      1|{{100.0, 0.0, 0.0...|Newark Airport|    EWR|POLYGON((-74.1856...|      132.96|\n",
      "+-------+--------------------+--------------+-------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_structured_arrayed\n",
    "    .withColumn('payments', F.explode('payments'))\n",
    "    .select(\"*\", \"payments.total_amount\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Extract contributions from `sdf_structured` into individual rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+-------+--------------------+-----------+-----+-------+----------+\n",
      "|zone_id|            payments|     zone_name|borough|           zone_geom|fare_amount|extra|mta_tax|tip_amount|\n",
      "+-------+--------------------+--------------+-------+--------------------+-----------+-----+-------+----------+\n",
      "|      1|{{162.5, 0.0, 0.0...|Newark Airport|    EWR|POLYGON((-74.1856...|      162.5|  0.0|    0.0|      28.0|\n",
      "|      1|{{95.0, 0.0, 0.0,...|Newark Airport|    EWR|POLYGON((-74.1856...|       95.0|  0.0|    0.0|       4.7|\n",
      "|      1|{{120.0, 0.0, 0.0...|Newark Airport|    EWR|POLYGON((-74.1856...|      120.0|  0.0|    0.0|      15.0|\n",
      "|      1|{{80.0, 0.0, 0.0,...|Newark Airport|    EWR|POLYGON((-74.1856...|       80.0|  0.0|    0.0|     19.05|\n",
      "|      1|{{100.0, 0.0, 0.0...|Newark Airport|    EWR|POLYGON((-74.1856...|      100.0|  0.0|    0.0|     22.16|\n",
      "+-------+--------------------+--------------+-------+--------------------+-----------+-----+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_structured_arrayed\n",
    "    .withColumn('payments', F.explode('payments'))\n",
    "    .select(\"*\", \"payments.contributions.*\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Format time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: keep only the rides that went over at least one night and change pickup and dropoff times to the format like `April 27, 1967`\n",
    "\n",
    "Make sure to exclude the ones traveling back in time (dropped off before picked up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------+--------------+--------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|date_diff|   pickup_date|  dropoff_date|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------+--------------+--------------+\n",
      "|        1|2018-05-18 23:46:46|2018-05-19 00:11:22|              1|          7.5|        1|                 N|           1|       24.5|  0.5|    0.5|      6.45|         0.0|          0.3|       32.25|               138|                237|        1|  May 18, 2018|  May 19, 2018|\n",
      "|        2|2018-05-08 23:45:38|2018-05-09 00:13:08|              2|         7.93|        1|                 N|           1|       27.0|  0.5|    0.5|      5.66|         0.0|          0.3|       33.96|                48|                244|        1|   May 8, 2018|   May 9, 2018|\n",
      "|        2|2018-03-20 23:45:09|2018-03-21 00:09:17|              1|         6.24|        1|                 N|           1|       21.5|  0.5|    0.5|      4.56|         0.0|          0.3|       27.36|               230|                129|        1|March 20, 2018|March 21, 2018|\n",
      "|        2|2018-04-09 23:36:47|2018-04-10 00:05:32|              1|         6.59|        1|                 N|           1|       24.0|  0.5|    0.5|      5.06|         0.0|          0.3|       30.36|               230|                255|        1| April 9, 2018|April 10, 2018|\n",
      "|        2|2018-04-09 23:34:47|2018-04-10 00:11:51|              2|        19.03|        1|                 N|           1|       53.0|  0.5|    0.5|     13.58|         0.0|          0.3|       67.88|               249|                 37|        1| April 9, 2018|April 10, 2018|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"date_diff\",\n",
    "        F.datediff('dropoff_datetime', 'pickup_datetime')\n",
    "    )\n",
    "    .filter(F.col(\"date_diff\") > 0)\n",
    "    .withColumn('pickup_date', F.date_format(F.col(\"pickup_datetime\"), 'MMMM d, yyy'))\n",
    "    .withColumn('dropoff_date', F.date_format(F.col(\"dropoff_datetime\"), 'MMMM d, yyy'))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: keep only the weekend rides (started on either Saturday or Sunday) and specify which day it was in the corresponding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+-----------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|day_of_week|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+-----------+\n",
      "|        1|2018-05-19 00:20:08|2018-05-19 00:56:25|              1|          6.4|        1|                 N|           1|       26.5|  0.5|    0.5|       4.0|         0.0|          0.3|        31.8|               249|                226|   Saturday|\n",
      "|        1|2018-05-19 00:58:26|2018-05-19 01:23:38|              1|         18.5|        1|                 N|           1|       50.0|  0.5|    0.5|     15.35|         0.0|          0.3|       66.65|               132|                255|   Saturday|\n",
      "|        2|2018-05-19 01:45:41|2018-05-19 02:16:45|              1|         8.24|        1|                 N|           1|       27.5|  0.5|    0.5|       7.2|         0.0|          0.3|        36.0|               114|                260|   Saturday|\n",
      "|        1|2018-05-19 01:57:50|2018-05-19 02:13:06|              1|          7.5|        1|                 N|           1|       22.5|  0.5|    0.5|      8.85|        5.76|          0.3|       38.41|               158|                257|   Saturday|\n",
      "|        2|2018-05-19 01:35:51|2018-05-19 02:08:15|              6|         8.03|        1|                 N|           1|       27.5|  0.5|    0.5|       7.2|         0.0|          0.3|        36.0|               249|                223|   Saturday|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"day_of_week\",\n",
    "        F.dayofweek('pickup_datetime')\n",
    "    )\n",
    "    .filter(F.col(\"day_of_week\").isin([1, 7]))\n",
    "    .withColumn(\n",
    "        \"day_of_week\",\n",
    "        F.when(F.col(\"day_of_week\") == 1, F.lit(\"Sunday\"))\n",
    "        .otherwise(F.lit(\"Saturday\"))\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Unix time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: keep only the rides that ended on the day corresponding to the following unix timestamp `1521552311`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|        1|2018-03-20 20:31:34|2018-03-20 21:08:54|              1|          6.7|        1|                 N|           1|       27.0|  0.5|    0.5|       4.0|         0.0|          0.3|        32.3|               161|                181|\n",
      "|        2|2018-03-20 20:37:49|2018-03-20 21:07:51|              2|         9.58|        1|                 N|           1|       31.5|  0.5|    0.5|       8.2|         0.0|          0.3|        41.0|               138|                 61|\n",
      "|        1|2018-03-20 21:01:16|2018-03-20 21:40:13|              1|         12.6|        1|                 Y|           1|       41.0|  0.5|    0.5|      8.95|        2.64|          0.3|       53.89|               161|                200|\n",
      "|        2|2018-03-20 21:21:52|2018-03-20 21:40:49|              1|         7.76|        1|                 N|           1|       25.0|  0.5|    0.5|      5.26|         0.0|          0.3|       31.56|               237|                 13|\n",
      "|        2|2018-03-20 04:47:24|2018-03-20 05:14:55|              1|         7.39|        1|                 N|           1|       26.0|  0.5|    0.5|       4.1|         0.0|          0.3|        31.4|               186|                 97|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .filter(F.to_date(\"dropoff_datetime\") == F.to_date(F.from_unixtime(F.lit(\"1521552311\"))))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: find the date corresponding twice the unix pickup date for each ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|ts_doubled|doubled_date|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+------------+\n",
      "|        2|2018-02-01 19:45:04|2018-02-01 19:45:06|              2|          0.0|        5|                 N|           1|      186.5|  0.0|    0.5|     37.46|         0.0|          0.3|      224.76|               264|                265|3035021408|  2066-03-05|\n",
      "|        1|2018-04-10 09:24:34|2018-04-10 09:59:54|              1|          4.2|        1|                 N|           1|       24.5|  0.0|    0.5|      5.05|         0.0|          0.3|       30.35|               140|                234|3046690148|  2066-07-18|\n",
      "|        1|2018-12-27 16:14:59|2018-12-27 16:57:03|              1|          2.3|        1|                 N|           1|       22.5|  1.0|    0.5|      4.85|         0.0|          0.3|       29.15|               236|                230|3091847398|  2067-12-23|\n",
      "|        1|2018-07-23 08:45:46|2018-07-23 09:22:36|              1|         11.6|        1|                 N|           1|       36.0|  0.0|    0.5|      7.35|         0.0|          0.3|       44.15|               132|                 61|3064656692|  2067-02-11|\n",
      "|        2|2018-07-23 12:50:10|2018-07-23 13:25:16|              1|         3.62|        1|                 N|           1|       22.0|  0.0|    0.5|      4.56|         0.0|          0.3|       27.36|               234|                262|3064686020|  2067-02-11|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"ts_doubled\",\n",
    "        2*F.unix_timestamp('pickup_datetime')\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"doubled_date\",\n",
    "        F.to_date(F.from_unixtime(F.col(\"ts_doubled\")))\n",
    "    )\n",
    "    .sample(0.01)\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Drying the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: rewrite the example in part 3 with window defined in a separate variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|row_number|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+\n",
      "|        1|2018-12-31 15:04:52|2018-12-31 15:05:25|              1|         13.2|        5|                 N|           1|      162.5|  0.0|    0.0|      28.0|         0.0|          0.3|       190.8|                 1|                  1|         1|\n",
      "|        1|2018-12-31 14:07:13|2018-12-31 14:07:28|              2|          0.5|        5|                 N|           1|       95.0|  0.0|    0.0|       4.7|         0.0|          0.3|       100.0|                 1|                  1|         2|\n",
      "|        1|2018-12-31 13:36:54|2018-12-31 13:37:16|              2|          0.9|        5|                 N|           1|      120.0|  0.0|    0.0|      15.0|         0.0|          0.3|       135.3|                 1|                  1|         3|\n",
      "|        2|2018-12-29 22:57:08|2018-12-29 23:33:25|              5|        20.78|        2|                 N|           2|       52.0|  0.0|    0.5|       0.0|         0.0|          0.3|        52.8|                 2|                144|         1|\n",
      "|        2|2018-12-17 17:50:00|2018-12-17 18:47:54|              2|        18.24|        2|                 N|           1|       52.0|  4.5|    0.5|     11.46|         0.0|          0.3|       68.76|                 2|                143|         2|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "window_pickup = Window.partitionBy(\"pickup_location_id\").orderBy(F.desc(\"pickup_datetime\"))\n",
    "\n",
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\"row_number\", F.row_number().over(window_pickup))\n",
    "    .filter(F.col(\"row_number\") < 4)\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: rewrite the task from part 3 with window defined in a separate variable\n",
    "\n",
    "**Extra credit**: rewrite the filtering condition as a separate variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/01 14:12:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 71:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|payment_type|trips_count|\n",
      "+------------+-----------+\n",
      "|           1|         10|\n",
      "|           3|         14|\n",
      "|           4|         54|\n",
      "|           5|       NULL|\n",
      "|           2|         10|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "TO_ACCUMULATE = 5\n",
    "window_payment_type = Window.partitionBy(\"payment_type\").orderBy(F.col(\"pickup_datetime\")).rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "limit_cum_mta = F.col(\"cumulative_mta_tax\") <= TO_ACCUMULATE\n",
    "\n",
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"cumulative_mta_tax\",\n",
    "        F.sum(\"mta_tax\")\n",
    "        .over(window_payment_type)\n",
    "    )\n",
    "    .filter(limit_cum_mta)\n",
    "    .groupBy(\"payment_type\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips_count\"),\n",
    "        F.max(\"cumulative_mta_tax\").alias(\"max_cum\")\n",
    "    )\n",
    "    .select(\n",
    "        \"payment_type\",\n",
    "        F.when(F.col(\"max_cum\") >= TO_ACCUMULATE, F.col(\"trips_count\"))\n",
    "        .otherwise(F.lit(None))\n",
    "        .alias(\"trips_count\")\n",
    "    )\n",
    ").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Parameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: multiply each of the monetary columns by the number of symbols in the column name and add this value to the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+----------------+---------+-----------+---------------+-----------------+------------------+-----------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount * 11|extra * 5|mta_tax * 7|tip_amount * 10|tolls_amount * 12|imp_surcharge * 13|total_amount * 12|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+----------------+---------+-----------+---------------+-----------------+------------------+-----------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "|        2|2018-03-29 13:37:13|2018-03-29 14:17:01|              1|        18.15|        3|                 N|           1|           770.0|      0.0|        0.0|          161.6|            126.0|               3.9|          1163.52|       70.0|  0.0|    0.0|     16.16|        10.5|          0.3|       96.96|               161|                  1|\n",
      "|        2|2018-03-29 13:37:18|2018-03-29 14:15:33|              1|         4.59|        1|                 N|           1|           275.0|      0.0|        3.5|           51.6|              0.0|               3.9|           371.52|       25.0|  0.0|    0.5|      5.16|         0.0|          0.3|       30.96|                13|                230|\n",
      "|        2|2018-03-29 13:26:57|2018-03-29 13:28:03|              1|          0.3|        1|                 N|           1|            33.0|      0.0|        3.5|            7.6|              0.0|               3.9|            54.72|        3.0|  0.0|    0.5|      0.76|         0.0|          0.3|        4.56|               231|                231|\n",
      "|        2|2018-03-29 13:07:48|2018-03-29 14:03:05|              2|        16.97|        1|                 N|           1|           544.5|      0.0|        3.5|           56.1|            69.12|               3.9|           740.04|       49.5|  0.0|    0.5|      5.61|        5.76|          0.3|       61.67|               231|                138|\n",
      "|        2|2018-03-29 14:19:11|2018-03-29 15:19:59|              5|        14.45|        1|                 N|           1|           500.5|      0.0|        3.5|          104.1|            69.12|               3.9|           749.64|       45.5|  0.0|    0.5|     10.41|        5.76|          0.3|       62.47|                87|                138|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+----------------+---------+-----------+---------------+-----------------+------------------+-----------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sdf_trips\n",
    "    .select(\n",
    "        *sdf_trips.columns[:8],\n",
    "        *[(F.col(c)*len(c)).alias(f\"{c} * {len(c)}\") for c in sdf_trips.columns[8:-2]],\n",
    "        *sdf_trips.columns[8:-2],\n",
    "        *sdf_trips.columns[-2:],\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: rewrite the example from 5.1 by creating a function that takes the date time column name and returns the formatted output\n",
    "\n",
    "**Extra credit**: make the function work in a loop by providing a list of columns to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------+--------------+--------------+\n",
      "|vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|rate_code|store_and_fwd_flag|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|imp_surcharge|total_amount|pickup_location_id|dropoff_location_id|date_diff|   pickup_date|  dropoff_date|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------+--------------+--------------+\n",
      "|        1|2018-05-18 23:46:46|2018-05-19 00:11:22|              1|          7.5|        1|                 N|           1|       24.5|  0.5|    0.5|      6.45|         0.0|          0.3|       32.25|               138|                237|        1|  May 18, 2018|  May 19, 2018|\n",
      "|        2|2018-05-08 23:45:38|2018-05-09 00:13:08|              2|         7.93|        1|                 N|           1|       27.0|  0.5|    0.5|      5.66|         0.0|          0.3|       33.96|                48|                244|        1|   May 8, 2018|   May 9, 2018|\n",
      "|        2|2018-03-20 23:45:09|2018-03-21 00:09:17|              1|         6.24|        1|                 N|           1|       21.5|  0.5|    0.5|      4.56|         0.0|          0.3|       27.36|               230|                129|        1|March 20, 2018|March 21, 2018|\n",
      "|        2|2018-04-09 23:36:47|2018-04-10 00:05:32|              1|         6.59|        1|                 N|           1|       24.0|  0.5|    0.5|      5.06|         0.0|          0.3|       30.36|               230|                255|        1| April 9, 2018|April 10, 2018|\n",
      "|        2|2018-04-09 23:34:47|2018-04-10 00:11:51|              2|        19.03|        1|                 N|           1|       53.0|  0.5|    0.5|     13.58|         0.0|          0.3|       67.88|               249|                 37|        1| April 9, 2018|April 10, 2018|\n",
      "+---------+-------------------+-------------------+---------------+-------------+---------+------------------+------------+-----------+-----+-------+----------+------------+-------------+------------+------------------+-------------------+---------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transform_date(col):\n",
    "    return F.date_format(F.col(col), 'MMMM d, yyy')\n",
    "\n",
    "(\n",
    "    sdf_trips\n",
    "    .withColumn(\n",
    "        \"date_diff\",\n",
    "        F.datediff('dropoff_datetime', 'pickup_datetime')\n",
    "    )\n",
    "    .filter(F.col(\"date_diff\") > 0)\n",
    "    .select(\n",
    "        \"*\",\n",
    "        *[transform_date(col).alias(col[:-4])\n",
    "          for col in sdf_trips.columns\n",
    "          if \"datetime\" in col]\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: calculate the number of combinations of rides such that the drop off location for one is the pick up location for another\n",
    "\n",
    "**Hint**: stop the execution if spent more than 5 minutes waiting and proceed to the following task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_pairs = (\n",
    "    sdf_trips\n",
    "    .select(\n",
    "        F.col(\"pickup_location_id\").alias(\"pickup_location_id_a\"),\n",
    "        F.col(\"dropoff_location_id\").alias(\"dropoff_location_id_a\"),\n",
    "        F.col(\"dropoff_location_id\").alias(\"to_join\"),\n",
    "    )\n",
    "    .join(\n",
    "        sdf_trips\n",
    "        .select(\n",
    "            F.col(\"pickup_location_id\").alias(\"pickup_location_id_b\"),\n",
    "            F.col(\"dropoff_location_id\").alias(\"dropoff_location_id_b\"),\n",
    "            F.col(\"pickup_location_id\").alias(\"to_join\"),\n",
    "        ),\n",
    "        on=\"to_join\",\n",
    "        how='inner',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the combinations\n",
    "# print(f\"{sdf_sampled_pairs.count()=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: prototype the code in example for the 0.1% sample of the rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf_sampled_pairs.count()=2,992,180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf_trips_sample = sdf_trips.sample(0.001)\n",
    "\n",
    "sdf_sampled_pairs = (\n",
    "    sdf_trips_sample\n",
    "    .select(\n",
    "        F.col(\"pickup_location_id\").alias(\"pickup_location_id_a\"),\n",
    "        F.col(\"dropoff_location_id\").alias(\"dropoff_location_id_a\"),\n",
    "        F.col(\"dropoff_location_id\").alias(\"to_join\"),\n",
    "    )\n",
    "    .join(\n",
    "        sdf_trips_sample\n",
    "        .select(\n",
    "            F.col(\"pickup_location_id\").alias(\"pickup_location_id_b\"),\n",
    "            F.col(\"dropoff_location_id\").alias(\"dropoff_location_id_b\"),\n",
    "            F.col(\"pickup_location_id\").alias(\"to_join\"),\n",
    "        ),\n",
    "        on=\"to_join\",\n",
    "        how='inner',\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"{sdf_sampled_pairs.count()=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Saving intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: For the task in 7.1: save the first 0.1% of rides before joining it to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_trips_sample = sdf_trips.sample(0.001)\n",
    "\n",
    "# (\n",
    "#     sdf_trips_sample\n",
    "#     .write.mode(\"overwrite\")\n",
    "#     .option(\"overwriteSchema\", \"True\")\n",
    "#     .format(\"parquet\")\n",
    "#     .saveAsTable(\"sdf_trips_sample\")\n",
    "# )\n",
    "\n",
    "# To be continued\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: process at least 10 batches of the 0.1% samples to get the corresponding scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Duck typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: make `.prc()` applied to a dataframe print row count of that dataframe and test it on `sdf_trips` dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:>                                                       (0 + 10) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,000,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.dataframe import DataFrame\n",
    "\n",
    "def _prc(self):\n",
    "    print(f\"{self.count():,}\")\n",
    "\n",
    "DataFrame.prc = _prc\n",
    "\n",
    "sdf_trips.prc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: make `.pvc(col)` applied to a dataframe return another dataframe with row count for each unique entry in the column `col` and test it on `sdf_geo` dataset column `borough`\n",
    "\n",
    "**Extra credit** the dataframe should also contain a column for the percentage of each unique entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+----------+\n",
      "|      borough|count|percentage|\n",
      "+-------------+-----+----------+\n",
      "|       Queens|   69|     26.2%|\n",
      "|    Manhattan|   69|     26.2%|\n",
      "|     Brooklyn|   61|     23.2%|\n",
      "|        Bronx|   43|     16.3%|\n",
      "|Staten Island|   20|      7.6%|\n",
      "|          EWR|    1|      0.4%|\n",
      "+-------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _pvc(self, col):\n",
    "    return (\n",
    "        self\n",
    "        .withColumn('total_count', F.count(\"*\").over(Window.partitionBy(F.lit(1))))\n",
    "        .groupBy(col)\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"count\"),\n",
    "            F.format_string('%.1f%%', 100*F.count(\"*\")/F.max('total_count')).alias(\"percentage\"),\n",
    "        )\n",
    "        .sort(F.desc(\"count\"))\n",
    "    )\n",
    "\n",
    "DataFrame.pvc = _pvc\n",
    "\n",
    "sdf_geo.pvc('borough').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_training",
   "language": "python",
   "name": "pyspark_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
